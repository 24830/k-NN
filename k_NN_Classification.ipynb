{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TimeSeriesClustering_ChangeFinder_100data_BeforAfterChange1sec\n",
    "#検知したデータを用いてDTW-kmeans(100個)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import changefinder\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "with tf.device('/device:GPU:0'): #GPU使用\n",
    "    \n",
    "    def make_all_ppg_array(data,original_data):\n",
    "        time=0\n",
    "        for line in original_data:\n",
    "\n",
    "            if time < 12000 :\n",
    "                data[time] = int(line.split()[3])#何列目とってくるか\n",
    "                time += 1\n",
    "                \n",
    "        return data\n",
    "\n",
    "\n",
    "    def Anomaly_Detection(ppg,answer,label):\n",
    "\n",
    "        data =np.zeros((12000),int)#データ格納用\n",
    "        det_data = np.zeros((0,det_data_len),int)#検知データ格納用\n",
    "        sub_det_data = np.zeros((det_data_len),int) #検知データ作成用\n",
    "\n",
    "\n",
    "        data = make_all_ppg_array(data,ppg)\n",
    "\n",
    "        #とりあえず描画\n",
    "        plt.plot(data, linestyle = \"dashed\" , label=\"acc\")\n",
    "        plt.xlabel('Epochs',fontsize = 18)\n",
    "        plt.ylabel('Accuracy',fontsize = 18)\n",
    "        plt.legend()\n",
    "        plt.tick_params()\n",
    "        plt.show()\n",
    "\n",
    "        cf = changefinder.ChangeFinder(r=0.01, order=1, smooth=7)\n",
    "\n",
    "        score = np.zeros((12000),int)\n",
    "        score_num = 0\n",
    "        for i in data:\n",
    "            sub_score = cf.update(i)\n",
    "            score[score_num] = sub_score\n",
    "            score_num += 1\n",
    "\n",
    "        \n",
    "        det_time=0\n",
    "        det_data_num=0\n",
    "        wait_F = 0\n",
    "        for t in range(0,len(score)):\n",
    "            if score[t] > 60 and wait_F == 0 and t>2000:\n",
    "                print(f\"record:{t}\")\n",
    "                for k in range(t-100,t+100):\n",
    "                    sub_det_data[det_time] = data[k]\n",
    "                    det_time += 1\n",
    "                det_time = 0\n",
    "                det_data = np.r_[det_data,sub_det_data.reshape(1,-1)]\n",
    "                answer_list.append(answer)\n",
    "                label_list.append(label)\n",
    "                wait_F = 1\n",
    "            elif wait_F > 0 :\n",
    "                wait_F += 1\n",
    "                if wait_F > 501 :\n",
    "                    wait_F = 0\n",
    "\n",
    "        print(det_data)\n",
    "\n",
    "\n",
    "\n",
    "        # プロット\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(score)\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.plot(data,'r')\n",
    "        plt.show()\n",
    "        \n",
    "        return det_data\n",
    "\n",
    "    det_data_len = 200\n",
    "    get_data = np.zeros((10,det_data_len),int)\n",
    "    answer_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    with open(\"gu_sampling100ms_relax7s_act3s_2byte.txt\") as ppg:\n",
    "        get_data = Anomaly_Detection(ppg,\"gu\",0)\n",
    "    \n",
    "    with open(\"choki_sampling100ms_relax7s_act3s_2byte.txt\") as ppg:\n",
    "        get_data= np.concatenate([get_data,Anomaly_Detection(ppg,\"choki\",1)],0)\n",
    "        \n",
    "    with open(\"par_sampling100ms_relax7s_act3s_2byte.txt\") as ppg:\n",
    "        get_data= np.concatenate([get_data,Anomaly_Detection(ppg,\"par\",2)],0)\n",
    "        \n",
    "    with open(\"onerev_sampling100ms_relax7s_act3s_2byte.txt\") as ppg:\n",
    "        get_data= np.concatenate([get_data,Anomaly_Detection(ppg,\"one\",3)],0)\n",
    "        \n",
    "    with open(\"three_sampling100ms_relax7s_act3s_2byte.txt\") as ppg:\n",
    "        get_data= np.concatenate([get_data,Anomaly_Detection(ppg,\"three\",4)],0)\n",
    "        \n",
    "    with open(\"four_sampling100ms_relax7s_act3s_2byte.txt\") as ppg:\n",
    "        get_data= np.concatenate([get_data,Anomaly_Detection(ppg,\"four\",5)],0)\n",
    "        \n",
    "    with open(\"fox_sampling100ms_relax7s_act3s_2byte.txt\") as ppg:\n",
    "        get_data= np.concatenate([get_data,Anomaly_Detection(ppg,\"fox\",6)],0)\n",
    "        \n",
    "    with open(\"phone_sampling100ms_relax7s_act3s_2byte.txt\") as ppg:\n",
    "        get_data= np.concatenate([get_data,Anomaly_Detection(ppg,\"phone\",7)],0)\n",
    "        \n",
    "    with open(\"goodrev_sampling100ms_relax7s_act3s_2byte.txt\") as ppg:\n",
    "        get_data= np.concatenate([get_data,Anomaly_Detection(ppg,\"good\",8)],0)\n",
    "        \n",
    "    with open(\"koyubirev_sampling100ms_relax7s_act3s_2byte.txt\") as ppg:\n",
    "        get_data= np.concatenate([get_data,Anomaly_Detection(ppg,\"koyubi\",9)],0)\n",
    "    \n",
    "    #k分割交差検証\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    for train_index, eval_index in kf.split(get_data,label_list):\n",
    "        X_train, X_test = get_data[train_index], get_data[eval_index]\n",
    "        Y_train, Y_test = label_list[train_index], label_list[eval_index]\n",
    "        \n",
    "        accuracy_list = []\n",
    "        sns.set()\n",
    "        k_range = range(1, 10)\n",
    "        for k in k_range:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k)\n",
    "            knn.fit(X_train, Y_train)\n",
    "            Y_pred = knn.predict(X_test)\n",
    "            accuracy_list.append(metrics.accuracy_score(Y_test, Y_pred))\n",
    "            print(confusion_matrix(Y_test,Y_pred)) #混同行列を作成\n",
    "\n",
    "        figure = plt.figure()\n",
    "        ax = figure.add_subplot(111)\n",
    "        ax.plot(k_range, accuracy_list)\n",
    "        ax.set_xlabel('k-nn')\n",
    "        ax.set_ylabel('accuracy')\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
